{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import re\n",
    "import os\n",
    "import h5py\n",
    "import lightning.pytorch as pl\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_fn_short_val import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "config = yaml.safe_load(open(\"hypertune.yaml\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_encode_path = config['class_encode_path']\n",
    "truncated_label_path = config['truncated_label_path']\n",
    "truncated_embed_path = config['truncated_embed_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_tool = Validation_tool(class_encode_path) # provide your own class_encode.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_METALS = len(val_tool.class_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = os.listdir(truncated_label_path)\n",
    "LABEL_TEST_INX = [i for i in range(len(labels)) if 'test' in labels[i]][0]\n",
    "test_label_name = labels[LABEL_TEST_INX]\n",
    "del labels[LABEL_TEST_INX]\n",
    "LABEL_POS_INX = [i for i in range(len(labels)) if 'pos' in labels[i]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zn(2+)                   |3399\n",
      "Mg(2+)                   |1350\n",
      "[4Fe-4S] cluster         |537\n",
      "Ca(2+)                   |2758\n",
      "Mn(2+)                   |679\n",
      "a divalent metal cation  |8648\n",
      "Fe cation                |686\n",
      "[2Fe-2S] cluster         |227\n",
      "Cu cation                |415\n",
      "K(+)                     |97\n",
      "Ni(2+)                   |47\n",
      "Na(+)                    |79\n",
      "Fe(3+)                   |82\n",
      "iron-sulfur cluster      |791\n",
      "Cu(2+)                   |16\n",
      "Fe(2+)                   |15\n",
      "Co(2+)                   |32\n",
      "a metal cation           |9850\n",
      "neg                      |1056314\n"
     ]
    }
   ],
   "source": [
    "val_tool.dataset_class_summary(f'{truncated_label_path}{labels[LABEL_POS_INX]}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read embedding files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = os.listdir(truncated_embed_path)\n",
    "EMBED_TEST_INX = [i for i in range(len(embeds)) if 'test' in embeds[i]][0]\n",
    "test_embeds_name = embeds[EMBED_TEST_INX]\n",
    "del embeds[EMBED_TEST_INX] \n",
    "EMBED_POS_INX = [i for i in range(len(embeds)) if 'pos' in embeds[i]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5files = [h5py.File(f\"{truncated_embed_path}{embeds[i]}\", 'r') for i in range(len(embeds))]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not enough data to divide ['CHEBI:29033', 'Fe(2+)'], add to all split!\n"
     ]
    }
   ],
   "source": [
    "five_fold_splits = [val_tool.five_fold_val_split(f\"{truncated_label_path}{labels[i]}\") for i in range(len(labels))]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fold generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_files = [np.load(f\"{truncated_label_path}{labels[i]}\") for i in range(len(labels))]\n",
    "label = {}\n",
    "for f in label_files:\n",
    "    for k, v in f.items():\n",
    "        label[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_generator():\n",
    "    for i in range(5):\n",
    "        train_pos = five_fold_splits[LABEL_POS_INX][f'fold{i}']['train'].copy()\n",
    "        train_neg = [five_fold_splits[i][f'fold{i}']['train'].copy() for i in range(len(five_fold_splits)) if i != LABEL_POS_INX]\n",
    "\n",
    "        valid_acc = five_fold_splits[LABEL_POS_INX][f'fold{i}']['test'].copy()\n",
    "\n",
    "        for j in range(len(labels)-1):\n",
    "            if j != LABEL_POS_INX:\n",
    "                valid_acc.extend(five_fold_splits[j][f'fold{i}']['test'])\n",
    "        label_valid = {key: value for key, value in (label).items() if key in valid_acc}\n",
    "     \n",
    "        yield train_pos, train_neg, valid_acc, label_valid\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStreamDataset_over_sample_TFE:\n",
    "\n",
    "    def __init__(self, pos_acc, neg_acc_ls, labels, pos, neg=None, precision=np.float16):\n",
    "        self.pos_f = pos  # h5 file\n",
    "        self.labels = labels  # labels for both pos and neg\n",
    "        self.index = np.random.randint(0, len(neg_acc_ls))\n",
    "        print(f\"neg index: {self.index}\")\n",
    "        self.neg_f = neg[self.index]\n",
    "        self.acc_ls = pos_acc + neg_acc_ls[self.index]\n",
    "        self.pos_acc = list(self.pos_f.keys())\n",
    "        self.labels = labels  # labels for both pos and neg\n",
    "        self.dim = self.pos_f[list(self.pos_f.keys())[0]][()].shape[1]\n",
    "        self.precision = precision\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.acc_ls)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        acc = self.acc_ls[idx]\n",
    "        if acc in self.pos_acc:\n",
    "            embedding = self.pos_f[acc][()]\n",
    "        else:\n",
    "            embedding = self.neg_f[acc][()]\n",
    "\n",
    "        label = self.labels[acc]\n",
    "\n",
    "        prot_len = embedding.shape[0]\n",
    "\n",
    "        if label.shape == (1,):\n",
    "            label = np.zeros((N_METALS, prot_len), dtype=self.precision)\n",
    "\n",
    "        if self.precision == np.float16:\n",
    "            torch_type = torch.float16\n",
    "        else:\n",
    "            torch_type = torch.float32\n",
    "        return embedding, torch.tensor(label, dtype=torch_type)\n",
    "\n",
    "    def padding(self, batch, maxlen):\n",
    "        batch_protein_feat = []\n",
    "        batch_protein_mask = []\n",
    "        for protein_feat in batch:\n",
    "            padded_protein_feat = np.zeros((maxlen, self.dim))\n",
    "            padded_protein_feat[:protein_feat.shape[0]] = protein_feat\n",
    "            padded_protein_feat = torch.tensor(\n",
    "                padded_protein_feat, dtype=torch.float)\n",
    "            batch_protein_feat.append(padded_protein_feat)\n",
    "\n",
    "            protein_mask = np.zeros(maxlen)\n",
    "            protein_mask[:protein_feat.shape[0]] = 1\n",
    "            protein_mask = torch.tensor(protein_mask, dtype=torch.long)\n",
    "            batch_protein_mask.append(protein_mask)\n",
    "\n",
    "        return torch.stack(batch_protein_feat), torch.stack(batch_protein_mask)\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        features, labels = zip(*batch)\n",
    "        max_batch_len = max([x.shape[0] for x in features])\n",
    "        features, masks = self.padding(features, max_batch_len)\n",
    "        return features, torch.hstack(labels), masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStreamDataset_TFE:\n",
    "    def __init__(self, acc_ls, labels, files, precision=np.float16):\n",
    "        self.files = files  # h5 file\n",
    "        self.acc_ls = acc_ls\n",
    "        self.labels = labels  # labels for both pos and neg\n",
    "        f0 = self.files[0]\n",
    "        self.dim = f0[list(f0.keys())[0]][()].shape[1]\n",
    "        self.precision = precision\n",
    "        self.dc_ls = {i: files[i].keys() for i in range(len(files))}\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.acc_ls)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        acc = self.acc_ls[idx]\n",
    "        for i, f in self.dc_ls.items():\n",
    "            if acc in f:\n",
    "                embedding = self.files[i][acc][()]\n",
    "                break\n",
    "        label = self.labels[acc]\n",
    "\n",
    "        prot_len = embedding.shape[0]\n",
    "\n",
    "        if label.shape == (1,):\n",
    "            label = np.zeros((N_METALS, prot_len), dtype=self.precision)\n",
    "\n",
    "        if self.precision == np.float16:\n",
    "            torch_type = torch.float16\n",
    "        else:\n",
    "            torch_type = torch.float32\n",
    "        return embedding, torch.tensor(label, dtype=torch_type)\n",
    "\n",
    "    def padding(self, batch, maxlen):\n",
    "        batch_protein_feat = []\n",
    "        batch_protein_mask = []\n",
    "        for protein_feat in batch:\n",
    "            padded_protein_feat = np.zeros((maxlen, self.dim))\n",
    "            padded_protein_feat[:protein_feat.shape[0]] = protein_feat\n",
    "            padded_protein_feat = torch.tensor(\n",
    "                padded_protein_feat, dtype=torch.float)\n",
    "            batch_protein_feat.append(padded_protein_feat)\n",
    "\n",
    "            protein_mask = np.zeros(maxlen)\n",
    "            protein_mask[:protein_feat.shape[0]] = 1\n",
    "            protein_mask = torch.tensor(protein_mask, dtype=torch.long)\n",
    "            batch_protein_mask.append(protein_mask)\n",
    "\n",
    "        return torch.stack(batch_protein_feat), torch.stack(batch_protein_mask)\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        features, labels = zip(*batch)\n",
    "        max_batch_len = max([x.shape[0] for x in features])\n",
    "        features, masks = self.padding(features, max_batch_len)\n",
    "        return features, torch.hstack(labels), masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Self_Attention(nn.Module):\n",
    "    def __init__(self, num_hidden, num_heads=4, weight_matrix=False):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_head_size = int(num_hidden / num_heads)\n",
    "        self.all_head_size = self.num_heads * self.attention_head_size\n",
    "        self.wq = nn.Linear(num_hidden, self.all_head_size)\n",
    "        self.wk = nn.Linear(num_hidden, self.all_head_size)\n",
    "        self.wv = nn.Linear(num_hidden, self.all_head_size)\n",
    "        self.wo = nn.Linear(self.all_head_size, num_hidden)\n",
    "        self.weight_matrix = weight_matrix\n",
    "\n",
    "    def transpose_for_scores(self, x):\n",
    "        new_x_shape = x.size()[:-1] + (self.num_heads,\n",
    "                                       self.attention_head_size)\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        if self.weight_matrix:\n",
    "            q = self.transpose_for_scores(self.wq(q))\n",
    "            k = self.transpose_for_scores(self.wk(k))\n",
    "            v = self.transpose_for_scores(self.wv(v))\n",
    "        else:\n",
    "            q = self.transpose_for_scores(q)\n",
    "            k = self.transpose_for_scores(k)\n",
    "            v = self.transpose_for_scores(v)\n",
    "\n",
    "        attention_scores = torch.matmul(q, k.transpose(-1, -2))\n",
    "\n",
    "        if mask is not None:\n",
    "            attention_mask = (1.0 - mask) * -10000\n",
    "            attention_scores = attention_scores + \\\n",
    "                attention_mask.unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "        attention_scores = nn.Softmax(dim=-1)(attention_scores)\n",
    "\n",
    "        outputs = torch.matmul(attention_scores, v)\n",
    "\n",
    "        outputs = outputs.permute(0, 2, 1, 3).contiguous()\n",
    "        new_output_shape = outputs.size()[:-2] + (self.all_head_size,)\n",
    "        outputs = outputs.view(*new_output_shape)\n",
    "        if self.weight_matrix:\n",
    "            outputs = self.wo(outputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, num_hidden, num_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.W_in = nn.Linear(num_hidden, num_ff, bias=True)\n",
    "        self.W_out = nn.Linear(num_ff, num_hidden, bias=True)\n",
    "\n",
    "    def forward(self, h_V):\n",
    "        h = F.leaky_relu(self.W_in(h_V))\n",
    "        h = self.W_out(h)\n",
    "        return h\n",
    "\n",
    "\n",
    "class TransformerLayer(nn.Module):\n",
    "    def __init__(self, num_hidden=64, num_heads=4, dropout=0.2):\n",
    "        super(TransformerLayer, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.norm = nn.ModuleList(\n",
    "            [nn.LayerNorm(num_hidden, eps=1e-6) for _ in range(2)])\n",
    "\n",
    "        self.attention = Self_Attention(num_hidden, num_heads)\n",
    "        self.dense = PositionWiseFeedForward(num_hidden, num_hidden * 4)\n",
    "\n",
    "    def forward(self, h_V, mask=None):\n",
    "        dh = self.attention(h_V, h_V, h_V, mask)\n",
    "        h_V = self.norm[0](h_V + self.dropout(dh))\n",
    "\n",
    "        dh = self.dense(h_V)\n",
    "        h_V = self.norm[1](h_V + self.dropout(dh))\n",
    "\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(-1)\n",
    "            h_V = mask * h_V\n",
    "        return h_V\n",
    "\n",
    "\n",
    "class MetalBPredictor(nn.Module):\n",
    "    def __init__(self, feature_dim, hidden_dim=64, num_encoder_layers=2, num_heads=4, dropout=0.2):\n",
    "        super(MetalBPredictor, self).__init__()\n",
    "\n",
    "        self.input_block = nn.Sequential(\n",
    "            nn.LayerNorm(feature_dim, eps=1e-6), nn.Linear(feature_dim,\n",
    "                                                           hidden_dim), nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "        self.hidden_block = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_dim, eps=1e-6), nn.Dropout(dropout), nn.Linear(\n",
    "                hidden_dim, hidden_dim), nn.LeakyReLU(), nn.LayerNorm(hidden_dim, eps=1e-6)\n",
    "        )\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            TransformerLayer(hidden_dim, num_heads, dropout)\n",
    "            for _ in range(num_encoder_layers)\n",
    "        ])\n",
    "\n",
    "        self.dense = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out_proj = nn.Linear(hidden_dim, N_METALS)\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def forward(self, protein_feat, mask):\n",
    "        h_V = self.input_block(protein_feat)\n",
    "        h_V = self.hidden_block(h_V)\n",
    "\n",
    "        for layer in self.encoder_layers:\n",
    "            h_V = layer(h_V, mask)\n",
    "\n",
    "        x = self.dense(h_V)\n",
    "        x = self.dropout(x)\n",
    "        logits = self.out_proj(x)\n",
    "        logits = torch.flatten(logits, end_dim=1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(pl.LightningModule):\n",
    "    def __init__(self, train_pos, train_neg, feature_dim, hidden_dim=64, num_encoder_layers=2, num_heads=4, dropout=0.2, lr=1e-3, label_weight=[0.228, 5.802], batch_size=32, thres_tune=False):\n",
    "        super().__init__()\n",
    "        self.encoder = MetalBPredictor(\n",
    "            feature_dim, hidden_dim, num_encoder_layers, num_heads, dropout)\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.val_loss = 0\n",
    "        self.test_loss = 0\n",
    "        self.learning_rate = lr\n",
    "        self.label_weight = label_weight\n",
    "        self.batch_size = batch_size\n",
    "        self.train_pos = train_pos\n",
    "        self.train_neg = train_neg\n",
    "        self.val_y = []\n",
    "        self.val_pred = []\n",
    "        self.test_y = []\n",
    "        self.test_pred = []\n",
    "        self.thres_tune = thres_tune\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.encoder(x, mask)\n",
    "        return torch.squeeze(x)\n",
    "\n",
    "    def loss_fn(self, out, target):\n",
    "        weight = torch.ones_like(target)\n",
    "        weight[target == 0] = self.label_weight[0]\n",
    "        weight[target == 1] = self.label_weight[1]\n",
    "\n",
    "        return torch.nn.BCEWithLogitsLoss(reduction='none', weight=weight)(out, target).mean(axis=0).sum()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(), lr=self.learning_rate, weight_decay=1e-5)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=64)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, masks = batch\n",
    "        out = self(x, masks)\n",
    "        out = out[(torch.flatten(masks) == 1), :]\n",
    "        loss = self.loss_fn(out, y.T)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dataset = MyStreamDataset_over_sample_TFE(self.train_pos, self.train_neg, label, h5files[EMBED_POS_INX], [h5files[i] for i in range(len(h5files)) if i != EMBED_POS_INX], precision=np.float32)\n",
    "\n",
    "        train_dataloader = torch.utils.data.DataLoader(\n",
    "            train_dataset, batch_size=self.batch_size, shuffle=True, collate_fn=train_dataset.collate_fn, drop_last=True)\n",
    "        return train_dataloader\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, masks = batch\n",
    "        out = self(x, masks)\n",
    "        out = out[(torch.flatten(masks) == 1), :]\n",
    "        loss = self.loss_fn(out, y.T)\n",
    "        self.val_loss += loss\n",
    "        self.val_y.append(y)\n",
    "        self.val_pred.append(out.T)\n",
    "\n",
    "    def on_validation_epoch_start(self):\n",
    "        self.val_loss = 0\n",
    "        self.val_y = []\n",
    "        self.val_pred = []\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        y = torch.hstack(self.val_y)\n",
    "        out = torch.hstack(self.val_pred)\n",
    "        out = torch.sigmoid(out)\n",
    "        y_true = y.detach().cpu().numpy()\n",
    "        y_pred = out.detach().cpu().numpy()\n",
    "        dc = val_tool.sum_full_metrics(y_true, y_pred, 0.5)\n",
    "        self.val_loss = self.val_loss / len(self.val_y)\n",
    "        loss = self.val_loss\n",
    "        print(f'Validation loss: {loss}')\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('MCC', dc['mean MCC'])\n",
    "        self.log('AUPR', dc['mean AUPR'])\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y, masks = batch\n",
    "        out = self(x, masks)\n",
    "        out = out[(torch.flatten(masks) == 1), :]\n",
    "        loss = self.loss_fn(out, y.T)\n",
    "        self.test_loss += loss\n",
    "        self.test_y.append(y)\n",
    "        self.test_pred.append(out.T)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        y = torch.hstack(self.test_y)\n",
    "        out = torch.hstack(self.test_pred)\n",
    "        out = torch.sigmoid(out)\n",
    "        y_true = y.detach().cpu().numpy()\n",
    "        y_pred = out.detach().cpu().numpy()\n",
    "        \n",
    "        if self.thres_tune:\n",
    "            self.y_true = y_true\n",
    "            self.y_pred = y_pred\n",
    "        else:\n",
    "            dc = val_tool.sum_2metrics(y_true, y_pred, 0.5)\n",
    "            val_tool.plot_pr_curve(y_true, y_pred)\n",
    "            self.test_loss = self.test_loss / len(self.test_y)\n",
    "            self.log('test_loss', self.test_loss)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyStreamDataset_over_sample_CNN:\n",
    "\n",
    "    def __init__(self, pos_acc, neg_acc_ls, labels, pos, neg=None, max_len=512, precision=np.float16):\n",
    "        self.pos_f = pos  # h5 file\n",
    "        self.labels = labels  # labels for both pos and neg\n",
    "        self.index = np.random.randint(0, len(neg_acc_ls))\n",
    "        print(f\"neg index: {self.index}\")\n",
    "        self.neg_f = neg[self.index]\n",
    "        self.acc_ls = pos_acc + neg_acc_ls[self.index]\n",
    "        self.pos_acc = list(self.pos_f.keys())\n",
    "        self.labels = labels  # labels for both pos and neg\n",
    "        self.dim = self.pos_f[list(self.pos_f.keys())[0]][()].shape[1]\n",
    "        self.max_len = max_len\n",
    "        self.precision = precision\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.acc_ls)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        acc = self.acc_ls[idx]\n",
    "        if acc in self.pos_acc:\n",
    "            embedding = self.pos_f[acc][()]\n",
    "        else:\n",
    "            embedding = self.neg_f[acc][()]\n",
    "\n",
    "        label = self.labels[acc]\n",
    "\n",
    "        prot_len = embedding.shape[0]\n",
    "\n",
    "        if label.shape == (1,):\n",
    "            label = np.zeros((N_METALS, prot_len), dtype=self.precision)\n",
    "\n",
    "        if self.precision == np.float16:\n",
    "            torch_type = torch.float16\n",
    "        else:\n",
    "            torch_type = torch.float32\n",
    "\n",
    "        features = np.zeros((self.dim, self.max_len), dtype=self.precision)\n",
    "        features[:, :prot_len] = np.transpose(embedding)\n",
    "        mask = np.zeros((self.max_len), dtype=bool)\n",
    "        mask[:prot_len] = True\n",
    "\n",
    "        return torch.tensor(features, dtype=torch_type), torch.tensor(label, dtype=torch_type), torch.tensor(mask, dtype=torch.bool)\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        features, labels, masks = zip(*batch)\n",
    "        return torch.stack(features), torch.hstack(labels), torch.hstack(masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStreamDataset_CNN:\n",
    "    def __init__(self, acc_ls, labels, files, max_len=512, precision=np.float16):\n",
    "        self.files = files  # h5 file\n",
    "        self.acc_ls = acc_ls\n",
    "        self.labels = labels  # labels for both pos and neg\n",
    "        f0 = self.files[0]\n",
    "        self.dim = f0[list(f0.keys())[0]][()].shape[1]\n",
    "        self.max_len = max_len\n",
    "        self.precision = precision\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.acc_ls)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        acc = self.acc_ls[idx]\n",
    "        for f in self.files:\n",
    "            f_acc = list(f.keys())\n",
    "            if acc in f_acc:\n",
    "                embedding = f[acc][()]\n",
    "                break\n",
    "        label = self.labels[acc]\n",
    "\n",
    "        prot_len = embedding.shape[0]\n",
    "\n",
    "        if label.shape == (1,):\n",
    "            label = np.zeros((N_METALS, prot_len), dtype=self.precision)\n",
    "\n",
    "        features = np.zeros((self.dim, self.max_len), dtype=self.precision)\n",
    "        features[:, :prot_len] = np.transpose(embedding)\n",
    "        mask = np.zeros((self.max_len), dtype=bool)\n",
    "        mask[:prot_len] = True\n",
    "        if self.precision == np.float16:\n",
    "            torch_type = torch.float16\n",
    "        else:\n",
    "            torch_type = torch.float32\n",
    "        return torch.tensor(features, dtype=torch_type), torch.tensor(label, dtype=torch_type), torch.tensor(mask, dtype=torch.bool)\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        features, labels, masks = zip(*batch)\n",
    "        return torch.stack(features), torch.hstack(labels), torch.hstack(masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1dModel(pl.LightningModule):\n",
    "    def __init__(self, train_pos, train_neg, in_channels, hidden_channel, kernel_size, hidden_layer_num, lr=1e-3, label_weight=[0.228, 5.802], batch_size=32, thres_tune=False):\n",
    "        super().__init__()\n",
    "        stride = 1\n",
    "        padding = int((kernel_size - 1) / 2)\n",
    "        modules = []\n",
    "        in_channel_ = in_channels\n",
    "        feature_channel_ = hidden_channel\n",
    "        for i in range(hidden_layer_num):\n",
    "            modules.append(torch.nn.Conv1d(in_channels=in_channel_, out_channels=feature_channel_, kernel_size=kernel_size,\n",
    "                                           stride=stride, padding=padding))\n",
    "            modules.append(torch.nn.ELU())\n",
    "            in_channel_ = feature_channel_\n",
    "            feature_channel_ = feature_channel_//2\n",
    "\n",
    "        modules.append(torch.nn.Conv1d(in_channels=in_channel_, out_channels=N_METALS,\n",
    "                                       kernel_size=kernel_size, stride=stride, padding=padding))\n",
    "\n",
    "        self.conv1 = torch.nn.Sequential(*modules)\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.val_loss = 0\n",
    "        self.test_loss = 0\n",
    "        self.learning_rate = lr\n",
    "        self.label_weight = label_weight\n",
    "        self.batch_size = batch_size\n",
    "        self.train_pos = train_pos\n",
    "        self.train_neg = train_neg\n",
    "        self.val_y = []\n",
    "        self.val_pred = []\n",
    "        self.test_y = []\n",
    "        self.test_pred = []\n",
    "        self.thres_tune = thres_tune\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return torch.squeeze(x)\n",
    "\n",
    "    def loss_fn(self, out, target):\n",
    "        weight = torch.ones_like(target)\n",
    "        weight[target == 0] = self.label_weight[0]\n",
    "        weight[target == 1] = self.label_weight[1]\n",
    "        return torch.nn.BCEWithLogitsLoss(reduction='none', weight=weight)(out, target).mean(axis=0).sum()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(), lr=self.learning_rate, weight_decay=1e-5)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=64)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, masks = batch\n",
    "        out = self(x)\n",
    "        out = torch.hstack([i for i in out])[:, masks].T\n",
    "        loss = self.loss_fn(out, y.T)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dataset = MyStreamDataset_over_sample_CNN(self.train_pos, self.train_neg, label, h5files[EMBED_POS_INX], [\n",
    "                                                    h5files[i] for i in range(len(h5files)) if i != EMBED_POS_INX], precision=np.float32)\n",
    "\n",
    "        train_dataloader = torch.utils.data.DataLoader(\n",
    "            train_dataset, batch_size=self.batch_size, shuffle=True, collate_fn=train_dataset.collate_fn, drop_last=True)\n",
    "        return train_dataloader\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, masks = batch\n",
    "        out = self(x)\n",
    "        out = torch.hstack([i for i in out])[:, masks]\n",
    "        loss = self.loss_fn(out.T, y.T)\n",
    "        self.val_loss += loss\n",
    "        self.val_y.append(y)\n",
    "        self.val_pred.append(out)\n",
    "\n",
    "    def on_validation_epoch_start(self):\n",
    "        self.val_loss = 0\n",
    "        self.val_y = []\n",
    "        self.val_pred = []\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        y = torch.hstack(self.val_y)\n",
    "        out = torch.hstack(self.val_pred)\n",
    "        out = torch.sigmoid(out)\n",
    "        y_true = y.detach().cpu().numpy()\n",
    "        y_pred = out.detach().cpu().numpy()\n",
    "        dc = val_tool.sum_full_metrics(y_true, y_pred, 0.5)\n",
    "        self.val_loss = self.val_loss / len(self.val_y)\n",
    "        loss = self.val_loss\n",
    "        print(f'Validation loss: {loss}')\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('MCC', dc['mean MCC'])\n",
    "        self.log('AUPR', dc['mean AUPR'])\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y, masks = batch\n",
    "        out = self(x)\n",
    "        out = torch.hstack([i for i in out])[:, masks]\n",
    "        loss = self.loss_fn(out.T, y.T)\n",
    "        self.test_loss += loss\n",
    "        self.test_y.append(y)\n",
    "        self.test_pred.append(out)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        y = torch.hstack(self.test_y)\n",
    "        out = torch.hstack(self.test_pred)\n",
    "        out = torch.sigmoid(out)\n",
    "        y_true = y.detach().cpu().numpy()\n",
    "        y_pred = out.detach().cpu().numpy()\n",
    "\n",
    "        if self.thres_tune:\n",
    "            self.y_true = y_true\n",
    "            self.y_pred = y_pred\n",
    "        else:\n",
    "            dc = val_tool.sum_2metrics(y_true, y_pred, 0.5)\n",
    "            val_tool.plot_pr_curve(y_true, y_pred)\n",
    "            self.test_loss = self.test_loss / len(self.test_y)\n",
    "            self.log('test_loss', self.test_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "MODEL = config['model']\n",
    "BATCH_SIZE = config['batch_size']\n",
    "\n",
    "if MODEL == 'CNN2L':\n",
    "\n",
    "    AUPR_ls = []\n",
    "\n",
    "    feature_dim = h5files[0][list(h5files[0].keys())[0]][()].shape[1]\n",
    "\n",
    "    hidden_channel_ls = config[MODEL]['hidden_channel']\n",
    "    hidden_layer_num_ls = config[MODEL]['hidden_layer_num']\n",
    "    kernel_size_ls = config[MODEL]['kernel_size']\n",
    "    lr_ls = config[MODEL]['lr']\n",
    "    label_weight_ls = [tuple(i) for i in config[MODEL]['label_weight']]\n",
    "\n",
    "    max_AUPR = 0\n",
    "\n",
    "    for i in itertools.product(hidden_channel_ls, kernel_size_ls, hidden_layer_num_ls, lr_ls, label_weight_ls):\n",
    "\n",
    "        one_hyp_AUPR = 0\n",
    "        paras = f\"feature_channel: {i[0]}, kernel_size: {i[1]}, hidden_layer_num: {i[2]}, lr: {i[3]}, label_weight: {i[4]}\"\n",
    "        print(paras)\n",
    "        with open('cnn_hyper.txt', 'a') as f:\n",
    "            f.write(paras + '\\n')\n",
    "\n",
    "        hidden_channel = i[0]\n",
    "        kernel_size = i[1]\n",
    "        hidden_layer_num = i[2]\n",
    "        lr = i[3]\n",
    "        label_weight = i[4]\n",
    "        fold_n = 1\n",
    "        for trp, trn, val, val_l in fold_generator():\n",
    "            print(f\"==================== fold {fold_n} ====================\")\n",
    "\n",
    "            val_dataset = MyStreamDataset_TFE(\n",
    "                val, val_l, h5files, precision=np.float32)\n",
    "            val_dataloader = torch.utils.data.DataLoader(\n",
    "                val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=val_dataset.collate_fn, drop_last=True)\n",
    "            model = Conv1dModel(trp, trn, feature_dim, hidden_channel,\n",
    "                                    kernel_size, hidden_layer_num, lr=lr, label_weight=label_weight, batch_size=BATCH_SIZE)\n",
    "            early_stopping = EarlyStopping(monitor='AUPR', patience=2, mode='max')\n",
    "            checkpoint_callback = ModelCheckpoint(\n",
    "                filename='{epoch}-{val_loss:.6f}-{MCC:.3f}-{AUPR:.3f}', save_top_k=3, monitor=\"AUPR\", save_last=True, mode='max')\n",
    "            trainer = pl.Trainer(accelerator='gpu', min_epochs=32, max_epochs = 300, precision=32, callbacks=[early_stopping, checkpoint_callback], check_val_every_n_epoch=10, reload_dataloaders_every_n_epochs=1)\n",
    "            trainer.fit(model=model, val_dataloaders=val_dataloader)\n",
    "            one_hyp_AUPR += trainer.callback_metrics['AUPR']\n",
    "            \n",
    "            one_fold_summary = f\"Fold {fold_n} val loss: {trainer.callback_metrics['val_loss']} AUPR: {trainer.callback_metrics['AUPR']}\"\n",
    "            print(one_fold_summary)\n",
    "            with open('cnn_hyper3.txt', 'a') as f:\n",
    "                f.write(one_fold_summary + '\\n')\n",
    "            fold_n += 1\n",
    "        \n",
    "        one_hyp_AUPR /= 5\n",
    "        AUPR_ls.append(one_hyp_AUPR)\n",
    "        if one_hyp_AUPR > max_AUPR:\n",
    "            max_AUPR = one_hyp_AUPR\n",
    "            best_AUPR_hyp = i\n",
    "\n",
    "        one_search_summary = f\"====================Hyper {i} AUPR: {one_hyp_AUPR} current best AUPR: {max_AUPR} ====================\" + \\\n",
    "            '\\n' + \\\n",
    "            f\"==================== Best AUPR hyper: {best_AUPR_hyp} ====================\" + '\\n'\n",
    "        with open('cnn_hyper.txt', 'a') as f:\n",
    "            f.write(one_search_summary)\n",
    "\n",
    "        print(one_search_summary)\n",
    "\n",
    "    \n",
    "elif MODEL == 'TFE':\n",
    "    AUPR_ls = []\n",
    "\n",
    "    feature_dim = h5files[0][list(h5files[0].keys())[0]][()].shape[1]\n",
    "    hidden_dim_ls = config[MODEL]['hidden_dim']\n",
    "    num_encoder_layers_ls = config[MODEL]['num_encoder_layers']\n",
    "    num_heads_ls = config[MODEL]['num_heads']\n",
    "    dropout_ls = config[MODEL]['dropout']\n",
    "    lr_ls = config[MODEL]['lr']\n",
    "    label_weight_ls = [tuple(i) for i in config[MODEL]['label_weight']]\n",
    "\n",
    "    max_AUPR = 0\n",
    "\n",
    "    for i in itertools.product(hidden_dim_ls, num_encoder_layers_ls, num_heads_ls, dropout_ls, lr_ls, label_weight_ls):\n",
    "        \n",
    "        one_hyp_AUPR = 0\n",
    "        paras = f\"hidden_dim: {i[0]}, num_encoder_layers: {i[1]}, num_heads: {i[2]}, dropout: {i[3]}, lr: {i[4]}, label_weight: {i[5]}\"\n",
    "        print(paras)\n",
    "        with open('transformer_hyp.txt', 'a') as f:\n",
    "            f.write(paras + '\\n')\n",
    "        hidden_dim = i[0]\n",
    "        num_encoder_layers = i[1]\n",
    "        num_heads = i[2]\n",
    "        dropout = i[3]\n",
    "        lr = i[4]\n",
    "        label_weight = i[5]\n",
    "        fold_n = 1\n",
    "        for trp, trn, val, val_l in fold_generator():\n",
    "            print(f\"==================== fold {fold_n} ====================\")\n",
    "\n",
    "            val_dataset = MyStreamDataset_TFE(\n",
    "                val, val_l, h5files, precision=np.float32)\n",
    "            val_dataloader = torch.utils.data.DataLoader(\n",
    "                val_dataset, batch_size=16, shuffle=False, collate_fn=val_dataset.collate_fn, drop_last=True)\n",
    "            model = TransformerModel(trp, trn, feature_dim, hidden_dim,\n",
    "                                    num_encoder_layers, num_heads, dropout, lr=lr, label_weight=label_weight, batch_size=BATCH_SIZE)\n",
    "            early_stopping = EarlyStopping(monitor='AUPR', patience=2, mode='max')\n",
    "            checkpoint_callback = ModelCheckpoint(\n",
    "                filename='{epoch}-{val_loss:.6f}-{MCC:.3f}-{AUPR:.3f}', save_top_k=3, monitor=\"AUPR\", save_last=True, mode='max')\n",
    "            trainer = pl.Trainer(accelerator='gpu', min_epochs=50, max_epochs = 300, precision=32, callbacks=[early_stopping, checkpoint_callback], check_val_every_n_epoch=10, reload_dataloaders_every_n_epochs=1)\n",
    "            trainer.fit(model=model, val_dataloaders=val_dataloader)\n",
    "            one_hyp_AUPR += trainer.callback_metrics['AUPR']\n",
    "\n",
    "            one_fold_summary = f\"Fold {fold_n} val loss: {trainer.callback_metrics['val_loss']} AUPR: {trainer.callback_metrics['AUPR']}\"\n",
    "            print(one_fold_summary)\n",
    "            with open('transformer_hyp.txt', 'a') as f:\n",
    "                f.write(one_fold_summary + '\\n')\n",
    "            fold_n += 1\n",
    "\n",
    "        one_hyp_AUPR /= 5\n",
    "        AUPR_ls.append(one_hyp_AUPR)\n",
    "        if one_hyp_AUPR > max_AUPR:\n",
    "            max_AUPR = one_hyp_AUPR\n",
    "            best_AUPR_hyp = i\n",
    "\n",
    "        one_search_summary = f\"==================== Hyper {i} AUPR: {one_hyp_AUPR} current best AUPR: {max_AUPR} ====================\" + \\\n",
    "            '\\n' + \\\n",
    "            f\"==================== Best AUPR hyper: {best_AUPR_hyp} ====================\" + '\\n'\n",
    "        with open('transformer_hyp.txt', 'a') as f:\n",
    "            f.write(one_search_summary)\n",
    "\n",
    "        print(one_search_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b268f936485e9642e47b6cb0ca892ff8ffff4521a885096470cb3093b046e1d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
